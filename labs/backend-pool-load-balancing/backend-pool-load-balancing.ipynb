{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM â¤ï¸ OpenAI\n",
    "\n",
    "## ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ—ãƒ¼ãƒ«è² è·åˆ†æ•£ ãƒ©ãƒœ\n",
    "![flow](../../images/backend-pool-load-balancing.gif)\n",
    "\n",
    "APIMã®[ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ—ãƒ¼ãƒ«æ©Ÿèƒ½](https://learn.microsoft.com/en-us/azure/api-management/backends?tabs=bicep)ã‚’ä½¿ç”¨ã—ã¦ã€Azure OpenAIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¾ãŸã¯ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒãƒ¼ã®ãƒªã‚¹ãƒˆã«å¯¾ã—ã¦çµ„ã¿è¾¼ã¿ã®è² è·åˆ†æ•£ã‚’è©¦ã™ãŸã‚ã®ãƒ—ãƒ¬ã‚¤ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã™ã€‚\n",
    "\n",
    "æ³¨æ„äº‹é …:\n",
    "- ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒ—ãƒ¼ãƒ«ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ­ãƒ“ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™\n",
    "- ã—ã‹ã—ã€å„ªå…ˆåº¦ã¨é‡ã¿ä»˜ã‘ã«åŸºã¥ããƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚‚ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã™: `openai_resources`å¤‰æ•°ã®`priority`ï¼ˆæ•°å€¤ãŒä½ã„ã»ã©å„ªå…ˆåº¦ãŒé«˜ã„ï¼‰ãŠã‚ˆã³`weight`ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ã—ã¦ãã ã•ã„\n",
    "- `retry` API Managementãƒãƒªã‚·ãƒ¼ã¯ã€HTTP 429ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰ãŒç™ºç”Ÿã—ãŸå ´åˆã«åˆ©ç”¨å¯èƒ½ãªãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã¸ã®å†è©¦è¡Œã‚’é–‹å§‹ã—ã¾ã™\n",
    "- `openai_resources`å¤‰æ•°ã‚’ã‚¯ãƒªã‚¢ã—ã¦ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒãƒ¼ã‚’ä½¿ç”¨ã—ã€[app.py](../../tools/mock-server/app.py)ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´ã—ã¦ã‚«ã‚¹ã‚¿ãƒ å‹•ä½œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã¾ã™\n",
    "\n",
    "### çµæœ\n",
    "![result](result.png)\n",
    "\n",
    "### ç›®æ¬¡\n",
    "- [0ï¸âƒ£ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å¤‰æ•°ã®åˆæœŸåŒ–](#0)\n",
    "- [1ï¸âƒ£ Azureãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ](#1)\n",
    "- [2ï¸âƒ£ ğŸ¦¾ Bicepã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ—ãƒ­ã‚¤ã®ä½œæˆ](#2)\n",
    "- [3ï¸âƒ£ ãƒ‡ãƒ—ãƒ­ã‚¤å‡ºåŠ›ã®å–å¾—](#3)\n",
    "- [ğŸ§ª ç›´æ¥HTTPã‚³ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦APIã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹](#requests)\n",
    "- [ğŸ” è² è·åˆ†æ•£çµæœã®åˆ†æ](#plot)\n",
    "- [ğŸ§ª Azure OpenAI Python SDKã‚’ä½¿ç”¨ã—ã¦APIã‚’ãƒ†ã‚¹ãƒˆã™ã‚‹](#sdk)\n",
    "- [ğŸ—‘ï¸ ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—](#clean)\n",
    "\n",
    "### å‰ææ¡ä»¶\n",
    "- [Python 3.8ä»¥é™ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³](https://www.python.org/)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "- [Pandasãƒ©ã‚¤ãƒ–ãƒ©ãƒª](https://pandas.pydata.org/)ãŠã‚ˆã³matplotlibãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "- [VS Code](https://code.visualstudio.com/)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã€[Jupyterãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯æ‹¡å¼µæ©Ÿèƒ½](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã“ã¨\n",
    "- [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "- Contributoræ¨©é™ã‚’æŒã¤[Azureã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³](https://azure.microsoft.com/en-us/free/)ãŒã‚ã‚‹ã“ã¨\n",
    "- [Azure OpenAIã¸ã®ã‚¢ã‚¯ã‚»ã‚¹](https://aka.ms/oai/access)ãŒè¨±å¯ã•ã‚Œã¦ã„ã‚‹ã‹ã€ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã“ã¨\n",
    "- [Azure CLIã§Azureã«ã‚µã‚¤ãƒ³ã‚¤ãƒ³](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively)ã—ã¦ã„ã‚‹ã“ã¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93mA web browser has been opened at https://login.microsoftonline.com/fdb5bdfe-92ed-4d5a-b697-a66439451bda/oauth2/v2.0/authorize. Please continue the login in the web browser. If no web browser is available or if the web browser fails to open, use device code flow with `az login --use-device-code`.\u001b[0m\n",
      "\n",
      "Retrieving subscriptions for the selection...\n",
      "\n",
      "[Tenant and subscription selection]\n",
      "\n",
      "No     Subscription name    Subscription ID                       Tenant\n",
      "-----  -------------------  ------------------------------------  ------------------------------------\n",
      "\u001b[96m[1]\u001b[0m *  \u001b[96mkoheisaito\u001b[0m           \u001b[96m59e7c4a1-e556-4873-87e6-ba29af832e01\u001b[0m  \u001b[96mfdb5bdfe-92ed-4d5a-b697-a66439451bda\u001b[0m\n",
      "\n",
      "The default is marked with an *; the default tenant is 'fdb5bdfe-92ed-4d5a-b697-a66439451bda' and subscription is 'koheisaito' (59e7c4a1-e556-4873-87e6-ba29af832e01).\n",
      "\n",
      "Select a subscription and tenant (Type a number or Enter for no changes): ^C\n"
     ]
    }
   ],
   "source": [
    "! az login --tenant \"fdb5bdfe-92ed-4d5a-b697-a66439451bda\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0ï¸âƒ£ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å¤‰æ•°ã®åˆæœŸåŒ–\n",
    "\n",
    "- ãƒªã‚½ãƒ¼ã‚¹ã¯ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³IDã«åŸºã¥ãä¸€æ„ã®æ–‡å­—åˆ—ã§ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã•ã‚Œã¾ã™\n",
    "- ```mock_webapps``` å¤‰æ•°ã¯ã€ãƒ¢ãƒƒã‚¯æ©Ÿèƒ½ã®ãŸã‚ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚ŒãŸWebã‚¢ãƒ—ãƒªã®ãƒªã‚¹ãƒˆã‚’è¨­å®šã—ã¾ã™ã€‚ãƒ¢ãƒƒã‚¯ã‚µãƒ¼ãƒ“ã‚¹ã§OpenAIã®å‹•ä½œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹ãŸã‚ã« ```openai_resources``` ãƒªã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¦ãã ã•ã„ã€‚\n",
    "- ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€[Azureãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã®è£½å“ã®åˆ©ç”¨å¯èƒ½æ€§](https://azure.microsoft.com/ja-jp/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management)ã«åŸºã¥ã„ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚\n",
    "- OpenAIãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ã€[ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã®åˆ©ç”¨å¯èƒ½æ€§](https://learn.microsoft.com/ja-jp/azure/ai-services/openai/concepts/models)ã«åŸºã¥ã„ã¦èª¿æ•´ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "resource_group_name = f\"lab-{deployment_name}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "apim_resource_name = \"apim\"\n",
    "apim_resource_location = \"westeurope\"\n",
    "apim_resource_sku = \"Basicv2\"\n",
    "openai_resources = [ {\"name\": \"openai1\", \"location\": \"uksouth\", \"priority\": 1, \"weight\": 80}, {\"name\": \"openai2\", \"location\": \"swedencentral\", \"priority\": 1, \"weight\": 10}, {\"name\": \"openai3\", \"location\": \"francecentral\", \"priority\": 1, \"weight\": 10} ] # list of OpenAI resources to deploy. Clear this list to use only the mock resources\n",
    "openai_resources_sku = \"S0\"\n",
    "openai_model_name = \"gpt-35-turbo\"\n",
    "openai_model_version = \"0613\"\n",
    "openai_deployment_name = \"gpt-35-turbo\"\n",
    "openai_api_version = \"2024-02-01\"\n",
    "openai_specification_url='https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/' + openai_api_version + '/inference.json'\n",
    "openai_backend_pool = \"openai-backend-pool\"\n",
    "mock_backend_pool = \"mock-backend-pool\"\n",
    "mock_webapps = [ {\"name\": \"openaimock1\", \"endpoint\": \"https://openaimock1.azurewebsites.net\", \"priority\": 1, \"weight\": 80}, {\"name\": \"openaimock2\", \"endpoint\": \"https://openaimock2.azurewebsites.net\", \"priority\": 1, \"weight\": 20} ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1ï¸âƒ£ Azureãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ\n",
    "ã“ã®ãƒ©ãƒœã§ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã¯ã€æŒ‡å®šã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã«ä½œæˆã•ã‚Œã¾ã™ã€‚æ—¢å­˜ã®ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Azure Resource Group  lab-backend-pool-load-balancing  created âŒš  14:14:20.836640\n"
     ]
    }
   ],
   "source": [
    "resource_group_stdout = ! az group create --name {resource_group_name} --location {resource_group_location}\n",
    "if resource_group_stdout.n.startswith(\"ERROR\"):\n",
    "    print(resource_group_stdout)\n",
    "else:\n",
    "    print(\"âœ… Azure Resource Group \", resource_group_name, \" created âŒš \", datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2ï¸âƒ£ ğŸ¦¾ Bicepã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ—ãƒ­ã‚¤ã®ä½œæˆ\n",
    "\n",
    "ã“ã®ãƒ©ãƒœã§ã¯ã€[Bicep](https://learn.microsoft.com/ja-jp/azure/azure-resource-manager/bicep/overview?tabs=bicep)ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å®£è¨€çš„ã«å®šç¾©ã—ã¾ã™ã€‚\n",
    "\n",
    "`openAIModelCapacity`ã¯æ„å›³çš„ã«ä½ãè¨­å®šã•ã‚Œã¦ãŠã‚Šï¼ˆ2kãƒˆãƒ¼ã‚¯ãƒ³/åˆ†ï¼‰ã€ãƒ­ãƒ¼ãƒ‰ãƒãƒ©ãƒ³ã‚µãƒ¼ã®ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’ç¤ºã™ãŸã‚ã«è¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(openai_resources) > 0:\n",
    "    backend_id = openai_backend_pool if len(openai_resources) > 1 else openai_resources[0].get(\"name\")\n",
    "elif len(mock_webapps) > 0:\n",
    "    backend_id = mock_backend_pool if len(mock_webapps) > 1 else mock_webapps[0].get(\"name\")\n",
    "\n",
    "with open(\"policy.xml\", 'r') as policy_xml_file:\n",
    "    policy_template_xml = policy_xml_file.read()\n",
    "    policy_xml = policy_template_xml.replace(\"{backend-id}\", backend_id)\n",
    "    policy_xml_file.close()\n",
    "open(\"policy.xml\", 'w').write(policy_xml)\n",
    "\n",
    "bicep_parameters = {\n",
    "  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "  \"contentVersion\": \"1.0.0.0\",\n",
    "  \"parameters\": {\n",
    "    \"mockWebApps\": { \"value\": mock_webapps },\n",
    "    \"mockBackendPoolName\": { \"value\": mock_backend_pool },\n",
    "    \"openAIBackendPoolName\": { \"value\": openai_backend_pool },\n",
    "    \"openAIConfig\": { \"value\": openai_resources },\n",
    "    \"openAIDeploymentName\": { \"value\": openai_deployment_name },\n",
    "    \"openAISku\": { \"value\": openai_resources_sku },\n",
    "    \"openAIModelName\": { \"value\": openai_model_name },\n",
    "    \"openAIModelVersion\": { \"value\": openai_model_version },\n",
    "    \"openAIModelCapacity\": { \"value\": 2 },\n",
    "    \"openAIAPISpecURL\": { \"value\": openai_specification_url },\n",
    "    \"apimResourceName\": { \"value\": apim_resource_name},\n",
    "    \"apimResourceLocation\": { \"value\": apim_resource_location},\n",
    "    \"apimSku\": { \"value\": apim_resource_sku}\n",
    "  }\n",
    "}\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "! az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file \"main.bicep\" --parameters \"params.json\"\n",
    "\n",
    "open(\"policy.xml\", 'w').write(policy_template_xml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3ï¸âƒ£ Get the deployment outputs\n",
    "\n",
    "We are now at the stage where we only need to retrieve the gateway URL and the subscription before we are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscriptionKey.value -o tsv\n",
    "apim_subscription_key = deployment_stdout.n\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceGatewayURL.value -o tsv\n",
    "apim_resource_gateway_url = deployment_stdout.n\n",
    "print(\"ğŸ‘‰ğŸ» API Gateway URL: \", apim_resource_gateway_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### ğŸ§ª Test the API using a direct HTTP call\n",
    "Requests is an elegant and simple HTTP library for Python that will be used here to make raw API requests and inspect the responses. \n",
    "\n",
    "You will not see HTTP 429s returned as API Management's `retry` policy will select an available backend. If no backends are viable, an HTTP 503 will be returned.\n",
    "\n",
    "Tip: Use the [tracing tool](../../tools/tracing.ipynb) to track the behavior of the backend pool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "runs = 20\n",
    "sleep_time_ms = 0\n",
    "url = apim_resource_gateway_url + \"/openai/deployments/\" + openai_deployment_name + \"/chat/completions?api-version=\" + openai_api_version\n",
    "api_runs = []\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"â–¶ï¸ Run:\", i+1, \"/\", runs)\n",
    "    \n",
    "    if len(openai_resources) > 0:\n",
    "        messages={\"messages\":[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "        ]}\n",
    "    elif len(mock_webapps) > 0:\n",
    "        messages={\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": {\n",
    "                        \"simulation\": {\n",
    "                            \"default\": {\"response_status_code\": 200, \"wait_time_ms\": 0},\n",
    "                            \"openaimock1.azurewebsites.net\": {\"response_status_code\": 429}\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = requests.post(url, headers = {'api-key':apim_subscription_key}, json = messages)\n",
    "    response_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"âŒš {response_time:.2f} seconds\")\n",
    "    # Check the response status code and apply formatting\n",
    "    if 200 <= response.status_code < 300:\n",
    "        status_code_str = '\\x1b[1;32m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and green\n",
    "    elif response.status_code >= 400:\n",
    "        status_code_str = '\\x1b[1;31m' + str(response.status_code) + \" - \" + response.reason + '\\x1b[0m'  # Bold and red\n",
    "    else:\n",
    "        status_code_str = str(response.status_code)  # No formatting\n",
    "\n",
    "    # Print the response status with the appropriate formatting\n",
    "    print(\"Response status:\", status_code_str)\n",
    "    \n",
    "    print(\"Response headers:\", response.headers)\n",
    "    \n",
    "    if \"x-ms-region\" in response.headers:\n",
    "        print(\"x-ms-region:\", '\\x1b[1;31m'+response.headers.get(\"x-ms-region\")+'\\x1b[0m') # this header is useful to determine the region of the backend that served the request\n",
    "        api_runs.append((response_time, response.headers.get(\"x-ms-region\")))\n",
    "    \n",
    "    if (response.status_code == 200):\n",
    "        data = json.loads(response.text)\n",
    "        print(\"Token usage:\", data.get(\"usage\"), \"\\n\")\n",
    "        print(\"ğŸ’¬ \", data.get(\"choices\")[0].get(\"message\").get(\"content\"), \"\\n\")\n",
    "    else:\n",
    "        print(response.text)   \n",
    "\n",
    "    time.sleep(sleep_time_ms/1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plot'></a>\n",
    "### ğŸ” Analyze Load Balancing results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "mpl.rcParams['figure.figsize'] = [15, 7]\n",
    "df = pd.DataFrame(api_runs, columns=['Response Time', 'Region'])\n",
    "df['Run'] = range(1, len(df) + 1)\n",
    "\n",
    "# Define a color map for each region\n",
    "color_map = {'UK South': 'lightpink', 'France Central': 'lightblue', 'Sweden Central': 'lightyellow', 'Region3': 'red', 'Region4': 'orange'}  # Add more regions and colors as needed\n",
    "\n",
    "# Plot the dataframe with colored bars\n",
    "ax = df.plot(kind='bar', x='Run', y='Response Time', color=[color_map.get(region, 'gray') for region in df['Region']], legend=False)\n",
    "\n",
    "# Add legend\n",
    "legend_labels = [plt.Rectangle((0, 0), 1, 1, color=color_map.get(region, 'gray')) for region in df['Region'].unique()]\n",
    "ax.legend(legend_labels, df['Region'].unique())\n",
    "\n",
    "plt.title('Load Balancing results')\n",
    "plt.xlabel('Runs')\n",
    "plt.ylabel('Response Time')\n",
    "plt.xticks(df['Run'], rotation=0)\n",
    "\n",
    "average = df['Response Time'].mean()\n",
    "plt.axhline(y=average, color='r', linestyle='--', label=f'Average: {average:.2f}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### ğŸ§ª Test the API using the Azure OpenAI Python SDK\n",
    "\n",
    "Repeat the same test using the Python SDK to ensure compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "runs = 9\n",
    "sleep_time_ms = 0\n",
    "\n",
    "for i in range(runs):\n",
    "    print(\"â–¶ï¸ Run: \", i+1)\n",
    "\n",
    "    if len(openai_resources) > 0:\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "        ]\n",
    "    elif len(mock_webapps) > 0:\n",
    "        messages=[\n",
    "                {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": {\n",
    "                        \"simulation\": {\n",
    "                            \"default\": {\"response_status_code\": 200, \"wait_time_ms\": 0},\n",
    "                            \"openaimock1.azurewebsites.net\": {\"response_status_code\": 429}\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "    client = AzureOpenAI(\n",
    "        azure_endpoint=apim_resource_gateway_url,\n",
    "        api_key=apim_subscription_key,\n",
    "        api_version=openai_api_version\n",
    "    )\n",
    "    start_time = time.time()\n",
    "    response = client.chat.completions.create(model=openai_model_name, messages=messages)\n",
    "    response_time = time.time() - start_time\n",
    "    print(f\"âŒš {response_time:.2f} seconds\")\n",
    "    print(\"ğŸ’¬ \", response.choices[0].message.content)\n",
    "    time.sleep(sleep_time_ms/1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### ğŸ—‘ï¸ Clean up resources\n",
    "\n",
    "When you're finished with the lab, you should remove all your deployed resources from Azure to avoid extra charges and keep your Azure subscription uncluttered.\n",
    "Use the [clean-up-resources notebook](clean-up-resources.ipynb) for that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
