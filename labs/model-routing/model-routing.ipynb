{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APIM â¤ï¸ OpenAI\n",
    "\n",
    "## ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ©ãƒœ\n",
    "![flow](../../images/model-routing.gif)\n",
    "\n",
    "Azure OpenAIãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åŸºã¥ã„ã¦ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã™ã‚‹ãŸã‚ã®ãƒ—ãƒ¬ã‚¤ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã€‚\n",
    "\n",
    "### ç›®æ¬¡\n",
    "- [0ï¸âƒ£ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å¤‰æ•°ã®åˆæœŸåŒ–](#0)\n",
    "- [1ï¸âƒ£ Azureãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ](#1)\n",
    "- [2ï¸âƒ£ ğŸ¦¾ Bicepã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ—ãƒ­ã‚¤ã®ä½œæˆ](#2)\n",
    "- [3ï¸âƒ£ ãƒ‡ãƒ—ãƒ­ã‚¤ã®å‡ºåŠ›ã‚’å–å¾—](#3)\n",
    "- [ğŸ§ª ç›´æ¥HTTPã‚³ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸAPIã®ãƒ†ã‚¹ãƒˆ](#requests)\n",
    "- [ğŸ§ª Azure OpenAI Python SDKã‚’ä½¿ç”¨ã—ãŸAPIã®ãƒ†ã‚¹ãƒˆ](#sdk)\n",
    "- [ğŸ—‘ï¸ ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—](#clean)\n",
    "\n",
    "### ãƒãƒƒã‚¯ãƒ­ã‚°\n",
    "- ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®æ”¹å–„\n",
    "\n",
    "### å‰ææ¡ä»¶\n",
    "- [Python 3.8ä»¥é™ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³](https://www.python.org/)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "- [Pandasãƒ©ã‚¤ãƒ–ãƒ©ãƒª](https://pandas.pydata.org/)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "- [VS Code](https://code.visualstudio.com/)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã€[Jupyterãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯æ‹¡å¼µæ©Ÿèƒ½](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)ãŒæœ‰åŠ¹ã«ãªã£ã¦ã„ã‚‹ã“ã¨\n",
    "- [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli)ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "- Contributoræ¨©é™ã‚’æŒã¤[Azureã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³](https://azure.microsoft.com/en-us/free/)ãŒã‚ã‚‹ã“ã¨\n",
    "- [Azure OpenAIã¸ã®ã‚¢ã‚¯ã‚»ã‚¹](https://aka.ms/oai/access)ãŒè¨±å¯ã•ã‚Œã¦ã„ã‚‹ã“ã¨\n",
    "- [Azure CLIã§Azureã«ã‚µã‚¤ãƒ³ã‚¤ãƒ³](https://learn.microsoft.com/en-us/cli/azure/authenticate-azure-cli-interactively)ã—ã¦ã„ã‚‹ã“ã¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='0'></a>\n",
    "### 0ï¸âƒ£ ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å¤‰æ•°ã®åˆæœŸåŒ–\n",
    "\n",
    "- ãƒªã‚½ãƒ¼ã‚¹ã¯ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³IDã«åŸºã¥ã„ãŸä¸€æ„ã®æ–‡å­—åˆ—ã§ã‚µãƒ•ã‚£ãƒƒã‚¯ã‚¹ã•ã‚Œã¾ã™\n",
    "- ãƒ­ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ã€[Azureãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã®è£½å“ã®åˆ©ç”¨å¯èƒ½æ€§](https://azure.microsoft.com/en-us/explore/global-infrastructure/products-by-region/?cdn=disable&products=cognitive-services,api-management)ã«åŸºã¥ã„ã¦èª¿æ•´ã—ã¦ãã ã•ã„\n",
    "- OpenAIãƒ¢ãƒ‡ãƒ«ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ã€[ãƒªãƒ¼ã‚¸ãƒ§ãƒ³ã”ã¨ã®åˆ©ç”¨å¯èƒ½æ€§](https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models)ã«åŸºã¥ã„ã¦èª¿æ•´ã—ã¦ãã ã•ã„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "deployment_name = os.path.basename(os.path.dirname(globals()['__vsc_ipynb_file__']))\n",
    "index = ''  # Set a matching value here and in clean-up-resources.ipynb if you want separate instances of the lab. This is helpful when tearing down resources and mitigating API Management's soft delete.\n",
    "resource_group_name = f\"lab-{deployment_name}{index}\" # change the name to match your naming style\n",
    "resource_group_location = \"westeurope\"\n",
    "\n",
    "# Define three OpenAI model and version combinations\n",
    "# https://learn.microsoft.com/en-us/azure/ai-services/openai/concepts/models#gpt-35\n",
    "# Please note that availability of models and versions is variable and that you may need to adjust the model and version names to match the available models and versions in your Azure subscription.\n",
    "# For this lab, we are using the following combinations based on PayGo availability on June 21, 2024:\n",
    "#\n",
    "#   1) GPT-3.5 Turbo 1106: France Central, Sweden Central\n",
    "#   2) GPT-3.5 Turbo 0125: North Central US, South Central US\n",
    "#   3) GPT-4o 2024-05-13: East US, West US\n",
    "\n",
    "openai_model_gpt_35_turbo_0125 = { \"name\": \"gpt-35-turbo\", \"version\": \"0125\" }\n",
    "openai_model_gpt_35_turbo_1106 = { \"name\": \"gpt-35-turbo\", \"version\": \"1106\" }\n",
    "openai_model_gpt_4o_20240513 = { \"name\": \"gpt-4o\", \"version\": \"2024-05-13\" }\n",
    "\n",
    "openai_model_1_name = \"gpt-35-turbo\"\n",
    "openai_model_1_version = \"1106\"\n",
    "openai_deployment_1_name = f\"{openai_model_1_name}-{openai_model_1_version}\"\n",
    "openai_resources_1 = [ {\"name\": \"oai-francecentral\", \"location\": \"francecentral\"}, {\"name\": \"oai-swedencentral\", \"location\": \"swedencentral\"} ]\n",
    "\n",
    "openai_model_2_name = \"gpt-35-turbo\"\n",
    "openai_model_2_version = \"0125\"\n",
    "openai_deployment_2_name = f\"{openai_model_2_name}-{openai_model_2_version}\"\n",
    "openai_resources_2 = [ {\"name\": \"oai-northcentralus\", \"location\": \"northcentralus\"}, {\"name\": \"oai-southcentralus\", \"location\": \"southcentralus\"} ]\n",
    "\n",
    "openai_model_3_name = \"gpt-4o\"\n",
    "openai_model_3_version = \"2024-05-13\"\n",
    "openai_deployment_3_name = f\"{openai_model_3_name}-{openai_model_3_version}\"\n",
    "openai_resources_3 = [ {\"name\": \"oai-eastus\", \"location\": \"eastus\"}, {\"name\": \"oai-westus\", \"location\": \"westus\"} ]\n",
    "\n",
    "# Define Azure OpenAI resources\n",
    "openai_resources_sku = \"S0\"\n",
    "openai_api_version = \"2024-02-01\"\n",
    "openai_specification_url='https://raw.githubusercontent.com/Azure/azure-rest-api-specs/main/specification/cognitiveservices/data-plane/AzureOpenAI/inference/stable/' + openai_api_version + '/inference.json'\n",
    "\n",
    "# Define Azure API Management\n",
    "apim_resource_name = \"apim\"\n",
    "apim_resource_location = \"westeurope\"\n",
    "apim_resource_sku = \"Basicv2\"\n",
    "\n",
    "# Define the Azure OpenAI backends and backend pools per Azure OpenAI model and version\n",
    "openai_backend_pool_1 = f\"oai-backend-pool-{openai_deployment_1_name}\"\n",
    "openai_backend_pool_2 = f\"oai-backend-pool-{openai_deployment_2_name}\"\n",
    "openai_backend_pool_3 = f\"oai-backend-pool-{openai_deployment_3_name}\"\n",
    "\n",
    "log_analytics_name = \"workspace\"\n",
    "app_insights_name = 'insights'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "### 1ï¸âƒ£ Azureãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã®ä½œæˆ\n",
    "ã“ã®ãƒ©ãƒœã§ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã¯ã€æŒ‡å®šã•ã‚ŒãŸãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã«ä½œæˆã•ã‚Œã¾ã™ã€‚æ—¢å­˜ã®ãƒªã‚½ãƒ¼ã‚¹ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "resource_group_stdout = ! az group create --name {resource_group_name} --location {resource_group_location} \n",
    "\n",
    "if resource_group_stdout.n.startswith(\"ERROR\"):\n",
    "    print(resource_group_stdout)\n",
    "else:\n",
    "    print(\"âœ… Azure Resource Group \", resource_group_name, \" created âŒš \", datetime.datetime.now().time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "### 2ï¸âƒ£ ğŸ¦¾ Bicepã‚’ä½¿ç”¨ã—ãŸãƒ‡ãƒ—ãƒ­ã‚¤ã®ä½œæˆ\n",
    "\n",
    "ã“ã®ãƒ©ãƒœã§ã¯ã€[Bicep](https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/overview?tabs=bicep)ã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ—ãƒ­ã‚¤ã•ã‚Œã‚‹ã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’å®£è¨€çš„ã«å®šç¾©ã—ã¾ã™ã€‚ç•°ãªã‚‹æ§‹æˆã‚’è©¦ã™ãŸã‚ã«ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚„[main.bicep](main.bicep)ã‚’ç›´æ¥å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(openai_resources_1) > 0:\n",
    "    backend_id_1 = openai_backend_pool_1 if len(openai_resources_1) > 1 else openai_resources_1[0].get(\"name\")\n",
    "if len(openai_resources_2) > 0:\n",
    "    backend_id_2 = openai_backend_pool_2 if len(openai_resources_2) > 1 else openai_resources_2[0].get(\"name\")\n",
    "if len(openai_resources_3) > 0:\n",
    "    backend_id_3 = openai_backend_pool_3 if len(openai_resources_3) > 1 else openai_resources_3[0].get(\"name\")\n",
    "\n",
    "with open(\"policy.xml\", 'r') as policy_xml_file:\n",
    "    policy_template_xml = policy_xml_file.read()\n",
    "    policy_xml = policy_template_xml.replace(\"{backend-id-1}\", backend_id_1).replace(\"{backend-id-2}\", backend_id_2).replace(\"{backend-id-3}\", backend_id_3)\n",
    "    policy_xml_file.close()\n",
    "open(\"policy.xml\", 'w').write(policy_xml)\n",
    "\n",
    "bicep_parameters = {\n",
    "  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentParameters.json#\",\n",
    "  \"contentVersion\": \"1.0.0.0\",\n",
    "  \"parameters\": {\n",
    "    \"openAIBackendPoolName_1\": { \"value\": openai_backend_pool_1 },\n",
    "    \"openAIBackendPoolName_2\": { \"value\": openai_backend_pool_2 },\n",
    "    \"openAIBackendPoolName_3\": { \"value\": openai_backend_pool_3 },\n",
    "    \"openAIConfig_1\": { \"value\": openai_resources_1 },\n",
    "    \"openAIConfig_2\": { \"value\": openai_resources_2 },\n",
    "    \"openAIConfig_3\": { \"value\": openai_resources_3 },\n",
    "    \"openAIDeploymentName_1\": { \"value\": openai_deployment_1_name },\n",
    "    \"openAIDeploymentName_2\": { \"value\": openai_deployment_2_name },\n",
    "    \"openAIDeploymentName_3\": { \"value\": openai_deployment_3_name },\n",
    "    \"openAISku\": { \"value\": openai_resources_sku },\n",
    "    \"openAIModelName_1\": { \"value\": openai_model_1_name },\n",
    "    \"openAIModelName_2\": { \"value\": openai_model_2_name },\n",
    "    \"openAIModelName_3\": { \"value\": openai_model_3_name },\n",
    "    \"openAIModelVersion_1\": { \"value\": openai_model_1_version },\n",
    "    \"openAIModelVersion_2\": { \"value\": openai_model_2_version },\n",
    "    \"openAIModelVersion_3\": { \"value\": openai_model_3_version },\n",
    "    \"openAIAPISpecURL\": { \"value\": openai_specification_url },\n",
    "    \"apimResourceName\": { \"value\": apim_resource_name},\n",
    "    \"apimResourceLocation\": { \"value\": apim_resource_location},\n",
    "    \"apimSku\": { \"value\": apim_resource_sku},\n",
    "    \"logAnalyticsName\": { \"value\": log_analytics_name },\n",
    "    \"applicationInsightsName\": { \"value\": app_insights_name },\n",
    "    \"index\": { \"value\": index}\n",
    "  }\n",
    "}\n",
    "with open('params.json', 'w') as bicep_parameters_file:\n",
    "    bicep_parameters_file.write(json.dumps(bicep_parameters))\n",
    "\n",
    "! az deployment group create --name {deployment_name} --resource-group {resource_group_name} --template-file \"main.bicep\" --parameters \"params.json\"\n",
    "\n",
    "open(\"policy.xml\", 'w').write(policy_template_xml)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "### 3ï¸âƒ£ ãƒ‡ãƒ—ãƒ­ã‚¤ã®å‡ºåŠ›ã‚’å–å¾—\n",
    "\n",
    "ãƒ†ã‚¹ãƒˆã®æº–å‚™ãŒæ•´ã†å‰ã«ã€ã‚²ãƒ¼ãƒˆã‚¦ã‚§ã‚¤URLã¨ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã‚’å–å¾—ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type: ignore\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimSubscriptionKey.value -o tsv\n",
    "apim_subscription_key = deployment_stdout.n\n",
    "\n",
    "# type: ignore\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.apimResourceGatewayURL.value -o tsv\n",
    "apim_resource_gateway_url = deployment_stdout.n\n",
    "print(\"ğŸ‘‰ğŸ» API Gateway URL: \", apim_resource_gateway_url)\n",
    "\n",
    "# type: ignore\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.logAnalyticsWorkspaceId.value -o tsv\n",
    "workspace_id = deployment_stdout.n\n",
    "print(\"ğŸ‘‰ğŸ» Workspace ID: \", workspace_id)\n",
    "\n",
    "# type: ignore\n",
    "deployment_stdout = ! az deployment group show --name {deployment_name} -g {resource_group_name} --query properties.outputs.applicationInsightsAppId.value -o tsv\n",
    "app_id = deployment_stdout.n\n",
    "print(\"ğŸ‘‰ğŸ» App ID: \", app_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='requests'></a>\n",
    "### ğŸ§ª ç›´æ¥HTTPã‚³ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãŸAPIã®ãƒ†ã‚¹ãƒˆ\n",
    "Requestsã¯ã€ã“ã“ã§ç”Ÿã®APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’è¡Œã„ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ¤œæŸ»ã™ã‚‹ãŸã‚ã«ä½¿ç”¨ã•ã‚Œã‚‹ã€ã‚¨ãƒ¬ã‚¬ãƒ³ãƒˆã§ã‚·ãƒ³ãƒ—ãƒ«ãªPythonç”¨ã®HTTPãƒ©ã‚¤ãƒ–ãƒ©ãƒªã§ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "runs = 2\n",
    "sleep_time_ms = 1000\n",
    "\n",
    "# Initialize a session for connection pooling\n",
    "session = requests.Session()\n",
    "\n",
    "def make_api_request(deployment_name, openai_resources, apim_subscription_key, apim_resource_gateway_url, openai_api_version, sleep_time_ms):\n",
    "    if len(openai_resources) > 0:\n",
    "        messages = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "            ]\n",
    "        }\n",
    "        url = f\"{apim_resource_gateway_url}/openai/deployments/{deployment_name}/chat/completions?api-version={openai_api_version}\"\n",
    "        response = session.post(url, headers={'api-key': apim_subscription_key}, json=messages)\n",
    "        print(\"url: \", url)\n",
    "        print(\"status code: \", response.status_code)\n",
    "        print(\"headers \", response.headers)\n",
    "        print(\"x-ms-region: \", response.headers.get(\"x-ms-region\"))  # Useful to determine the region of the backend\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(\"\\nresponse: \", data.get(\"choices\")[0].get(\"message\").get(\"content\"))\n",
    "        else:\n",
    "            print(response.text)\n",
    "        time.sleep(sleep_time_ms / 1000)\n",
    "\n",
    "# Define your deployments and resources\n",
    "deployments = [\n",
    "    {\"name\": openai_deployment_1_name, \"resources\": openai_resources_1},    # GPT-3.5 Turbo 1106\n",
    "    {\"name\": openai_deployment_2_name, \"resources\": openai_resources_2},    # GPT-3.5 Turbo 0125\n",
    "    {\"name\": openai_deployment_3_name, \"resources\": openai_resources_3},    # GPT-4o 2024-05-13\n",
    "]\n",
    "\n",
    "# Loop through each deployment and make the API request\n",
    "for deployment in deployments:\n",
    "    for i in range(runs):\n",
    "        print(f\"\\nâ–¶ï¸ Run: {i+1} for deployment {deployment['name']}\")\n",
    "        make_api_request(deployment['name'], deployment['resources'], apim_subscription_key, apim_resource_gateway_url, openai_api_version, sleep_time_ms)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sdk'></a>\n",
    "### ğŸ§ª Azure OpenAI Python SDKã‚’ä½¿ç”¨ã—ãŸAPIã®ãƒ†ã‚¹ãƒˆ\n",
    "OpenAPIã¯åºƒãä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹[Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒª](https://github.com/openai/openai-python)ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚ã“ã®ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã«ã¯ã€ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å‹å®šç¾©ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚ã“ã®ãƒ†ã‚¹ãƒˆã®ç›®çš„ã¯ã€APIMãŒOpenAIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ã‚·ãƒ¼ãƒ ãƒ¬ã‚¹ã«ãƒ—ãƒ­ã‚­ã‚·ã—ã€ãã®æ©Ÿèƒ½ã‚’å¦¨ã’ã‚‹ã“ã¨ãªãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã§ã™ã€‚\n",
    "- æ³¨æ„: ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œã™ã‚‹å‰ã«ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§```pip install openai```ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "runs = 2\n",
    "sleep_time_ms = 1000\n",
    "\n",
    "def make_openaisdk_request(deployment_name, openai_resources, apim_subscription_key, apim_resource_gateway_url, openai_api_version, sleep_time_ms):\n",
    "    from openai import AzureOpenAI\n",
    "    if len(openai_resources) > 0:\n",
    "        messages = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a sarcastic unhelpful assistant.\"},\n",
    "                {\"role\": \"user\", \"content\": \"Can you tell me the time, please?\"}\n",
    "            ]\n",
    "        }\n",
    "        client = AzureOpenAI(\n",
    "            azure_endpoint=apim_resource_gateway_url,\n",
    "            api_key=apim_subscription_key,\n",
    "            api_version=openai_api_version\n",
    "        )\n",
    "        response = client.chat.completions.create(model=openai_deployment_1_name, messages=messages)\n",
    "        print(response.choices[0].message.content)\n",
    "        time.sleep(sleep_time_ms/1000)\n",
    "\n",
    "# Define your deployments and resources\n",
    "deployments = [\n",
    "    {\"name\": openai_deployment_1_name, \"resources\": openai_resources_1},    # GPT-3.5 Turbo 1106\n",
    "    {\"name\": openai_deployment_2_name, \"resources\": openai_resources_2},    # GPT-3.5 Turbo 0125\n",
    "    {\"name\": openai_deployment_3_name, \"resources\": openai_resources_3},    # GPT-4o 2024-05-13\n",
    "]\n",
    "\n",
    "# Loop through each deployment and make the API request\n",
    "for deployment in deployments:\n",
    "    for i in range(runs):\n",
    "        print(f\"\\nâ–¶ï¸ Run: {i+1} for deployment {deployment['name']}\")\n",
    "        make_api_request(deployment['name'], deployment['resources'], apim_subscription_key, apim_resource_gateway_url, openai_api_version, sleep_time_ms)     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='portal'></a>\n",
    "### ğŸ” Azureãƒãƒ¼ã‚¿ãƒ«ã§ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ã‚’é–‹ã\n",
    "\n",
    "ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ãƒªã‚½ãƒ¼ã‚¹ã‚’é–‹ãã€ä½¿ç”¨çŠ¶æ³åˆ†æã‚’ç¢ºèªã—ã¦ã€ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚„ãã®ä»–ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ç¢ºèªã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "### ğŸ—‘ï¸ ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—\n",
    "\n",
    "ãƒ©ãƒœãŒçµ‚äº†ã—ãŸã‚‰ã€è¿½åŠ ã®æ–™é‡‘ã‚’é¿ã‘ã€Azureã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã‚’æ•´ç†ã™ã‚‹ãŸã‚ã«ã€ãƒ‡ãƒ—ãƒ­ã‚¤ã—ãŸã™ã¹ã¦ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’Azureã‹ã‚‰å‰Šé™¤ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚\n",
    "ãã®ãŸã‚ã«ã¯ã€[ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯](clean-up-resources.ipynb)ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
